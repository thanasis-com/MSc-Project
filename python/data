whole images, 41 , 0.02 0.00001 100 epochs mostly stable, trainerror: 0.065 testerror: 0.064
whole images, 41 , 0.02 0.00001 150 epochs unstable after 85, train:0.058 test:0.056
whole images, 41 , 0.02 0.00001 100 epochs wider input (839), very unstable from 50, train: 0.063 test: 0.077 <------terrible output
whole images, 41 , 0.02 0.0001	150 epochs lower momentum (0.7), absolutely stable, train: 0.11 test 0.067

!!!AFTER FIXING TRAINING ERROR
whole images, 41 , 0.02 0.0001  200 epochs lower momentum (0.7), stable until saturation (around 180), train: 0.10 test: 0.066 <------- probably reset weight decay to 0.00001
whole images, 41 , 0.01 0.00001 200 epochs lower momentum (0.7), absolutely stable, train: 0.070 test: 0.076 <-----bad output cause it needed much more time
whole images, 41 , 0.05 0.00001 100 epochs lower momentum (0.7), unstable after 60, train: 0.052, test: 0.070 <------bad result, both errors have to be low
whole images, 41 , 0.02 0.000001 100 epochs lower momentum (0.7), mostly stable but did not converge, train: 0.066, test: 0.76 <----bad output (needed more time)
whole images, 41 , 0.01 0.00001 500 epochs lower momentum (0.7), very stable, train: 0.053, test: 0.064 <----- fairly good result, have to train even more
whole images, 41 , 0.01 0.00001 800 epochs lower momentum (0.7), very stable, train: 0.048, test: 0.064 <-----can be trained even more
whole images, 41 , 0.01 0.00001 1000 epochs lower momentum (0.7), saturated at 0.070 train: 0.041, test: 0.078<----seems like this network can't go over 0.064

whole images, 41 , 0.01 0.00001 200 epochs lower momentum (0.7), saturated from epoch 60, train: 0.062, test: 0.084 <------this was trained without the initial conv layers

!!!AUGMENTING DATASET X 3 (lower momentum applies to all)
whole images, 123, 0.01 0.00001 200 epochs, very stable, train: 0.056, test: 0.064 <-----train more
whole images, 123, 0.01 0.00001 500 epochs, unstable after 280 but reached even 0.060, train: 0.040, test: 0.075
